{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988b89f4",
   "metadata": {},
   "source": [
    "2-1. Nate 뉴스기사 제목 스크래핑하기 (필수)\n",
    "https://news.nate.com/recent?mid=n0100\n",
    "최신뉴스, 정치 , 경제, 사회, 세계, IT/과학 \n",
    "6개의 섹션의 뉴스를 출력하는 함수를 생성하여 스크래핑 하기\n",
    "\n",
    "Image, 기사제목, 기사링크\n",
    "\n",
    "뉴스기사의 Image를 출력 하세요 \n",
    "1) Image의 절대경로와 상대 경로를 합치려면 urljoin 함수를 사용하세요.\n",
    "    from urllib.parse import urljoin\n",
    "\n",
    "2) Image 출력은 Image 클래스와 display 함수를 사용하세요.\n",
    "    from IPython.display import Image, display\n",
    "\n",
    "3) img 엘리먼트의 존재 여부를 체크하신 후에 src 속성의 이미지를 경로를 추출하기\n",
    "  => Image 가 없는 뉴스도 있기 때문에 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa4b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "'최신뉴스' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- 최신뉴스 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n",
      "\n",
      "==================================================\n",
      "'정치' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- 정치 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n",
      "\n",
      "==================================================\n",
      "'경제' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- 경제 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n",
      "\n",
      "==================================================\n",
      "'사회' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- 사회 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n",
      "\n",
      "==================================================\n",
      "'세계' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- 세계 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n",
      "\n",
      "==================================================\n",
      "'IT/과학' 뉴스 섹션 스크래핑 시작\n",
      "==================================================\n",
      "--- IT/과학 ---\n",
      "  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def scrape_nate_news(section_url, section_name):\n",
    "    \"\"\"\n",
    "    Nate 뉴스의 특정 섹션에서 기사 제목, 링크, 이미지를 스크래핑하는 함수. (2025-07-25 기준 수정)\n",
    "\n",
    "    Args:\n",
    "        section_url (str): 스크래핑할 뉴스 섹션의 URL.\n",
    "        section_name (str): 출력할 섹션의 이름.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 웹페이지 요청\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "        response = requests.get(section_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # UTF-8 인코딩 명시적 설정\n",
    "        response.encoding = 'utf-8'\n",
    "\n",
    "        # HTML 파싱\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 섹션 제목 출력 (구조 변경으로 이름 직접 출력)\n",
    "        print(f\"--- {section_name} ---\")\n",
    "\n",
    "        \n",
    "        news_list = soup.select('div.post-list div.post-item')\n",
    "\n",
    "        if not news_list:\n",
    "            print(\"  [기사를 가져올 수 없습니다. 페이지 구조를 확인하세요.]\")\n",
    "            return\n",
    "\n",
    "        for item in news_list:\n",
    "            #  기사 제목 및 링크 선택자 변경: 'h5.post-tit a'\n",
    "            title_element = item.select_one('h5.post-tit a')\n",
    "            \n",
    "            # 이미지 선택자 변경: 'div.post-thumb img'\n",
    "            img_element = item.select_one('div.post-thumb img')\n",
    "\n",
    "            if not title_element:\n",
    "                continue\n",
    "            \n",
    "            title = title_element.text.strip()\n",
    "            # href 속성이 전체 URL을 포함하므로 urljoin이 필요 없을 수 있으나, 안전을 위해 유지\n",
    "            link = urljoin(section_url, title_element['href'])\n",
    "\n",
    "            print(f\"■ 제목: {title}\")\n",
    "            print(f\"■ 링크: {link}\")\n",
    "\n",
    "            # 이미지 추출 및 출력\n",
    "            if img_element and img_element.has_attr('src'):\n",
    "                img_src = img_element['src']\n",
    "                # 이미 전체 URL을 가지고 있으므로, '//' 처리만 확인\n",
    "                if img_src.startswith('//'):\n",
    "                    img_src = 'https:' + img_src\n",
    "                \n",
    "                try:\n",
    "                    display(Image(url=img_src, width=150))\n",
    "                except Exception as e:\n",
    "                    print(f\"  [이미지를 표시할 수 없습니다: {e}]\")\n",
    "            else:\n",
    "                print(\"  [이미지 없음]\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"오류가 발생했습니다: {e}\")\n",
    "\n",
    "# --- 실행 부분 ---\n",
    "if __name__ == '__main__':\n",
    "    section_urls = {\n",
    "        \"최신뉴스\": \"https://news.nate.com/recent?mid=n0100\",\n",
    "        \"정치\": \"https://news.nate.com/recent?mid=n0101\",\n",
    "        \"경제\": \"https://news.nate.com/recent?mid=n0102\",\n",
    "        \"사회\": \"https://news.nate.com/recent?mid=n0103\",\n",
    "        \"세계\": \"https://news.nate.com/recent?mid=n0104\",\n",
    "        \"IT/과학\": \"https://news.nate.com/recent?mid=n0105\"\n",
    "    }\n",
    "\n",
    "    for section_name, url in section_urls.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"'{section_name}' 뉴스 섹션 스크래핑 시작\")\n",
    "        print(f\"{'='*50}\")\n",
    "        # ✨ 함수에 섹션 이름을 함께 전달\n",
    "        scrape_nate_news(url, section_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc533c6",
   "metadata": {},
   "source": [
    "2-2. 하나의 네이버 웹툰과 1개의 회차에 대한 Image 다운로드 하기 (필수)\n",
    ":  하나의 웹툰의 제목(title)과 회차번호(no),회차의URL(url) 을 입력으로 받는 함수를 선언합니다. \n",
    "   def download_one_episode(title,no,url):\n",
    "\n",
    "아래와 같이 호출합니다.\n",
    "download_one_episode('일렉시드',341,'https://comic.naver.com/webtoon/detail?titleId=717481&no=341&week=wed')\n",
    "\n",
    "img\\일렉시드\\341 디렉토리가 생성되며 , \n",
    "그 디렉토리 아래에 웹툰 image들이 다운로드 되도록 해주세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'img\\광마회귀\\160' 디렉토리를 생성했습니다.\n",
      "이미지 다운로드를 시작합니다...\n",
      "다운로드 완료: 001.jpg\n",
      "다운로드 완료: 002.jpg\n",
      "다운로드 완료: 003.jpg\n",
      "다운로드 완료: 004.jpg\n",
      "다운로드 완료: 005.jpg\n",
      "다운로드 완료: 006.jpg\n",
      "다운로드 완료: 007.jpg\n",
      "다운로드 완료: 008.jpg\n",
      "다운로드 완료: 009.jpg\n",
      "다운로드 완료: 010.jpg\n",
      "다운로드 완료: 011.jpg\n",
      "다운로드 완료: 012.jpg\n",
      "다운로드 완료: 013.jpg\n",
      "다운로드 완료: 014.jpg\n",
      "다운로드 완료: 015.jpg\n",
      "다운로드 완료: 016.jpg\n",
      "다운로드 완료: 017.jpg\n",
      "다운로드 완료: 018.jpg\n",
      "다운로드 완료: 019.jpg\n",
      "다운로드 완료: 020.jpg\n",
      "다운로드 완료: 021.jpg\n",
      "다운로드 완료: 022.jpg\n",
      "다운로드 완료: 023.jpg\n",
      "다운로드 완료: 024.jpg\n",
      "다운로드 완료: 025.jpg\n",
      "다운로드 완료: 026.jpg\n",
      "다운로드 완료: 027.jpg\n",
      "다운로드 완료: 028.jpg\n",
      "다운로드 완료: 029.jpg\n",
      "다운로드 완료: 030.jpg\n",
      "다운로드 완료: 031.jpg\n",
      "다운로드 완료: 032.jpg\n",
      "다운로드 완료: 033.jpg\n",
      "다운로드 완료: 034.jpg\n",
      "다운로드 완료: 035.jpg\n",
      "다운로드 완료: 036.jpg\n",
      "다운로드 완료: 037.jpg\n",
      "다운로드 완료: 038.jpg\n",
      "다운로드 완료: 039.jpg\n",
      "다운로드 완료: 040.jpg\n",
      "다운로드 완료: 041.jpg\n",
      "다운로드 완료: 042.jpg\n",
      "다운로드 완료: 043.jpg\n",
      "다운로드 완료: 044.jpg\n",
      "다운로드 완료: 045.jpg\n",
      "다운로드 완료: 046.jpg\n",
      "다운로드 완료: 047.jpg\n",
      "다운로드 완료: 048.jpg\n",
      "다운로드 완료: 049.jpg\n",
      "다운로드 완료: 050.jpg\n",
      "다운로드 완료: 051.jpg\n",
      "다운로드 완료: 052.jpg\n",
      "다운로드 완료: 053.jpg\n",
      "다운로드 완료: 054.jpg\n",
      "다운로드 완료: 055.jpg\n",
      "다운로드 완료: 056.jpg\n",
      "다운로드 완료: 057.jpg\n",
      "다운로드 완료: 058.jpg\n",
      "다운로드 완료: 059.jpg\n",
      "다운로드 완료: 060.jpg\n",
      "다운로드 완료: 061.jpg\n",
      "다운로드 완료: 062.jpg\n",
      "\n",
      "총 62개의 이미지를 'img\\광마회귀\\160'에 성공적으로 다운로드했습니다. 🎉\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_one_episode(title, no, url):\n",
    "    \"\"\"\n",
    "    네이버 웹툰의 한 회차 이미지를 모두 다운로드합니다.\n",
    "\n",
    "    :param title: 웹툰 제목 (폴더명으로 사용)\n",
    "    :param no: 회차 번호 (폴더명으로 사용)\n",
    "    :param url: 다운로드할 회차의 URL\n",
    "    \"\"\"\n",
    "    # 저장할 디렉토리 경로 설정 및 생성\n",
    "    # 예: img/광마회귀/160\n",
    "    save_path = os.path.join('img', title, str(no))\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    print(f\"'{save_path}' 디렉토리를 생성했습니다.\")\n",
    "\n",
    "    # 웹툰 페이지에 접속하기 위한 헤더 설정 (차단 방지)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Referer': url\n",
    "    }\n",
    "\n",
    "    # 웹툰 페이지의 HTML 가져오기\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # HTTP 오류가 발생하면 예외 발생\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"오류: 웹 페이지를 가져올 수 없습니다. {e}\")\n",
    "        return\n",
    "\n",
    "    # HTML 파싱하여 이미지 URL 추출\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    image_tags = soup.select('.wt_viewer img') # 웹툰 이미지를 담고 있는 태그 선택\n",
    "\n",
    "    if not image_tags:\n",
    "        print(\"오류: 이미지 태그를 찾을 수 없습니다. 페이지 구조가 변경되었을 수 있습니다.\")\n",
    "        return\n",
    "\n",
    "    # 각 이미지 다운로드\n",
    "    print(\"이미지 다운로드를 시작합니다...\")\n",
    "    for i, img_tag in enumerate(image_tags):\n",
    "        img_url = img_tag.get('src')\n",
    "        if not img_url:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 이미지 데이터 요청\n",
    "            img_response = requests.get(img_url, headers=headers)\n",
    "            img_response.raise_for_status()\n",
    "\n",
    "            # 파일명 설정 (예: 001.jpg, 002.jpg, ...)\n",
    "            file_name = f\"{i+1:03d}.jpg\"\n",
    "            file_path = os.path.join(save_path, file_name)\n",
    "\n",
    "            # 이미지 파일 저장\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(img_response.content)\n",
    "            \n",
    "            print(f\"다운로드 완료: {file_name}\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"오류: '{img_url}' 이미지 다운로드에 실패했습니다. {e}\")\n",
    "            \n",
    "    print(f\"\\n총 {len(image_tags)}개의 이미지를 '{save_path}'에 성공적으로 다운로드했습니다. 🎉\")\n",
    "\n",
    "\n",
    "# --- 함수 호출 예시 ---\n",
    "if __name__ == \"__main__\":\n",
    "    download_one_episode('광마회귀', 160, 'https://comic.naver.com/webtoon/detail?titleId=776601&no=160&week=fri')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
